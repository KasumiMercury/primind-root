services:
    web:
        build:
            context: ./web
            target: dev
            args:
                VITE_APP_VERSION: ${WEB_VERSION:-dev}
        command: ["pnpm", "run", "dev"]
        ports:
            - "5173:5173"
        env_file:
            - .env
        environment:
            NODE_ENV: development
            WATCHPACK_POLLING: "true"
        stdin_open: true
        tty: true
        networks:
            - primind_frontend

    central-backend:
        build:
            context: ./central-backend/
            dockerfile: ./Dockerfile
            target: dev
            args:
                VERSION: ${SERVICE_VERSION:-dev}
        volumes:
            - ./central-backend:/app
        env_file:
            - .env
        environment:
            - ENV=${ENV:-dev}
            - SERVICE_NAME=central-backend
            - PRIMIND_TASKS_URL=http://tasks-api:8080
            - REMIND_REGISTER_QUEUE_NAME=remind-register
            - REMIND_CANCEL_QUEUE_NAME=remind-cancel
            - OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
            - OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=prometheus:9090
        healthcheck:
            test: ["CMD", "/grpc_health_probe", "-addr=:8080"]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 120s
        depends_on:
            postgres-central:
                condition: service_healthy
            redis:
                condition: service_healthy
        networks:
            - primind_frontend
            - primind_backend

    postgres-central:
        image: postgres:18
        environment:
            POSTGRES_USER: primind_user
            POSTGRES_PASSWORD: primind_password
            POSTGRES_DB: primind_db
        volumes:
            - postgres_central_data:/var/lib/postgresql
        healthcheck:
            test:
                [
                    "CMD-SHELL",
                    "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB} || exit 1",
                ]
            interval: 10s
            timeout: 5s
            retries: 5
            start_period: 5s
        networks:
            - primind_backend

    migrate-central:
        image: arigaio/atlas:latest
        command: >
            migrate apply
            --url postgres://primind_user:primind_password@postgres-central:5432/primind_db?sslmode=disable
        depends_on:
            postgres-central:
                condition: service_healthy
        volumes:
            - ./central-backend/migrations/:/migrations
        networks:
            - primind_backend

    time-mgmt:
        build:
            context: ./time-mgmt
            dockerfile: ./Dockerfile
            target: dev
            args:
                VERSION: ${SERVICE_VERSION:-dev}
        volumes:
            - ./time-mgmt:/app
        env_file:
            - .env
        environment:
            - ENV=${ENV:-dev}
            - SERVICE_NAME=time-mgmt
            - POSTGRES_DSN=postgres://timemgmt_user:timemgmt_password@postgres-time-mgmt:5432/timemgmt_db?sslmode=disable
            - NATS_URL=nats://nats:4222
            - OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
            - OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=prometheus:9090
        healthcheck:
            test: ["CMD", "/grpc_health_probe", "-addr=:8080"]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 120s
        depends_on:
            postgres-time-mgmt:
                condition: service_healthy
            nats:
                condition: service_healthy
        networks:
            - primind_backend

    postgres-time-mgmt:
        image: postgres:18
        environment:
            POSTGRES_USER: timemgmt_user
            POSTGRES_PASSWORD: timemgmt_password
            POSTGRES_DB: timemgmt_db
        volumes:
            - postgres_time_mgmt_data:/var/lib/postgresql
        healthcheck:
            test:
                [
                    "CMD-SHELL",
                    "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB} || exit 1",
                ]
            interval: 10s
            timeout: 5s
            retries: 5
            start_period: 5s
        networks:
            - primind_backend

    migrate-time-mgmt:
        image: arigaio/atlas:latest
        command: >
            migrate apply
            --url postgres://timemgmt_user:timemgmt_password@postgres-time-mgmt:5432/timemgmt_db?sslmode=disable
        depends_on:
            postgres-time-mgmt:
                condition: service_healthy
        volumes:
            - ./time-mgmt/migrations/:/migrations
        networks:
            - primind_backend

    redis:
        image: redis:8
        command: ["redis-server", "--appendonly", "yes"]
        volumes:
            - redis_data:/data
        healthcheck:
            test: ["CMD", "redis-cli", "ping"]
            interval: 10s
            timeout: 5s
            retries: 5
            start_period: 5s
        networks:
            - primind_backend

    nats:
        image: nats:2.10-alpine
        command: ["--jetstream", "--store_dir=/data"]
        volumes:
            - nats_data:/data
        healthcheck:
            test: ["CMD", "nats-server", "--version"]
            interval: 10s
            timeout: 5s
            retries: 5
            start_period: 5s
        networks:
            - primind_backend

    throttling:
        build:
            context: ./throttling
            dockerfile: ./Dockerfile
            target: dev
            args:
                VERSION: ${SERVICE_VERSION:-dev}
        volumes:
            - ./throttling:/app
        env_file:
            - .env
        environment:
            - ENV=${ENV:-dev}
            - SERVICE_NAME=notification-throttling
            - REMIND_TIME_MANAGEMENT_URL=http://time-mgmt:8080
            - PRIMIND_TASKS_URL=http://tasks-api:8080
            - TASK_QUEUE_NAME=invoke
            - REDIS_ADDR=redis:6379
            - OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
            - OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=prometheus:9090
        healthcheck:
            test: ["CMD", "/grpc_health_probe", "-addr=:8080"]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 120s
        depends_on:
            time-mgmt:
                condition: service_started
            redis:
                condition: service_healthy
        networks:
            - primind_backend

    nats-bridge:
        build:
            context: ./nats-bridge
            dockerfile: ./Dockerfile
            target: dev
            args:
                VERSION: ${SERVICE_VERSION:-dev}
        volumes:
            - ./nats-bridge:/app
            - ./nats-bridge.json:/app/config.json:ro
        environment:
            - CONFIG_PATH=/app/config.json
            - ENV=${ENV:-dev}
            - SERVICE_NAME=nats-bridge
            - OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
            - OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=prometheus:9090
        healthcheck:
            test: ["CMD", "/grpc_health_probe", "-addr=:8080"]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 30s
        depends_on:
            nats:
                condition: service_healthy
            throttling:
                condition: service_started
            time-mgmt:
                condition: service_started
        networks:
            - primind_backend

    notification-invoker:
        build:
            context: ./notification-invoker
            dockerfile: ./Dockerfile
            target: dev
            args:
                VERSION: ${SERVICE_VERSION:-dev}
        volumes:
            - ./notification-invoker:/app
            - ${HOME}/.config/gcloud/application_default_credentials.json:/root/.config/gcloud/application_default_credentials.json:ro
        working_dir: /app
        tty: true
        stdin_open: true
        env_file:
            - .env
        environment:
            - GOOGLE_APPLICATION_CREDENTIALS=/root/.config/gcloud/application_default_credentials.json
            - ENV=${ENV:-dev}
            - SERVICE_NAME=notification-invoker
            - WEB_APP_BASE_URL=http://web:5173
            - OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
            - OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=prometheus:9090
        healthcheck:
            test: ["CMD", "/grpc_health_probe", "-addr=:8080"]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 120s
        networks:
            - primind_backend

    # Task Queue

    tasks-api:
        build:
            context: ./primind-tasks
            dockerfile: ./Dockerfile
            target: api
            args:
                VERSION: ${SERVICE_VERSION:-dev}
        environment:
            - REDIS_ADDR=redis:6379
            - API_PORT=8080
            - RETRY_COUNT=3
            - ENV=${ENV:-dev}
            - SERVICE_NAME=primind-tasks-api
            - OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
            - OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=prometheus:9090
        healthcheck:
            test: ["CMD", "/grpc_health_probe", "-addr=:8080"]
            interval: 10s
            timeout: 5s
            retries: 3
            start_period: 120s
        depends_on:
            redis:
                condition: service_healthy
        networks:
            - primind_backend

    tasks-worker-1:
        build:
            context: ./primind-tasks
            dockerfile: ./Dockerfile
            target: worker
            args:
                VERSION: ${SERVICE_VERSION:-dev}
        environment:
            - REDIS_ADDR=redis:6379
            - QUEUE_NAME=invoke
            - TARGET_ENDPOINT=http://notification-invoker:8080/notify
            - RETRY_COUNT=3
            - WORKER_CONCURRENCY=10
            - REQUEST_TIMEOUT=30s
            - ENV=${ENV:-dev}
            - SERVICE_NAME=primind-tasks-worker-invoke
            - OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
            - OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=prometheus:9090
        depends_on:
            redis:
                condition: service_healthy
            notification-invoker:
                condition: service_started
        networks:
            - primind_backend

    tasks-worker-2:
        build:
            context: ./primind-tasks
            dockerfile: ./Dockerfile
            target: worker
            args:
                VERSION: ${SERVICE_VERSION:-dev}
        environment:
            - REDIS_ADDR=redis:6379
            - QUEUE_NAME=remind-register
            - TARGET_ENDPOINT=http://time-mgmt:8080/api/v1/reminds
            - RETRY_COUNT=3
            - WORKER_CONCURRENCY=10
            - REQUEST_TIMEOUT=30s
            - ENV=${ENV:-dev}
            - SERVICE_NAME=primind-tasks-worker-remind-register
            - OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
            - OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=prometheus:9090
        depends_on:
            redis:
                condition: service_healthy
            time-mgmt:
                condition: service_started
        networks:
            - primind_backend

    tasks-worker-3:
        build:
            context: ./primind-tasks
            dockerfile: ./Dockerfile
            target: worker
            args:
                VERSION: ${SERVICE_VERSION:-dev}
        environment:
            - REDIS_ADDR=redis:6379
            - QUEUE_NAME=remind-cancel
            - TARGET_ENDPOINT=http://time-mgmt:8080/api/v1/reminds/cancel
            - RETRY_COUNT=3
            - WORKER_CONCURRENCY=10
            - REQUEST_TIMEOUT=30s
            - ENV=${ENV:-dev}
            - SERVICE_NAME=primind-tasks-worker-remind-cancel
            - OTEL_EXPORTER_OTLP_ENDPOINT=jaeger:4318
            - OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=prometheus:9090
        depends_on:
            redis:
                condition: service_healthy
            time-mgmt:
                condition: service_started
        networks:
            - primind_backend

    asynqmon:
        image: hibiken/asynqmon:latest
        ports:
            - "8081:8080"
        environment:
            - REDIS_ADDR=redis:6379
        depends_on:
            redis:
                condition: service_healthy
        networks:
            - primind_frontend
            - primind_backend

    jaeger:
        image: jaegertracing/jaeger:latest
        ports:
            - "16686:16686"
            - "4318:4318"
        environment:
            - COLLECTOR_OTLP_ENABLED=true
        networks:
            - primind_frontend
            - primind_backend

    prometheus:
        image: prom/prometheus:latest
        ports:
            - "9090:9090"
        volumes:
            - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
            - prometheus_data:/prometheus
        command:
            - "--config.file=/etc/prometheus/prometheus.yml"
            - "--storage.tsdb.path=/prometheus"
            - "--web.enable-lifecycle"
            - "--web.enable-otlp-receiver"
        networks:
            - primind_frontend
            - primind_backend

    grafana:
        image: grafana/grafana:latest
        ports:
            - "3000:3000"
        environment:
            - GF_SECURITY_ADMIN_USER=admin
            - GF_SECURITY_ADMIN_PASSWORD=admin
            - GF_USERS_ALLOW_SIGN_UP=false
        volumes:
            - grafana_data:/var/lib/grafana
            - ./grafana/provisioning:/etc/grafana/provisioning:ro
            - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
        depends_on:
            - prometheus
        networks:
            - primind_frontend
            - primind_backend

    scheduler:
        image: curlimages/curl:latest
        entrypoint: ["/bin/sh", "-c"]
        command:
            - |
                echo "Scheduler started - polling every 60 seconds"
                while true; do
                  echo "[$(date)] Triggering throttle..."
                  curl -s -X POST http://throttling:8080/api/v1/throttle || echo "Failed to call throttle API"
                  sleep 60
                done
        depends_on:
            - throttling
        networks:
            - primind_backend

networks:
    primind_frontend:
        name: primind_frontend
        driver: bridge
    primind_backend:
        name: primind_backend
        driver: bridge

volumes:
    postgres_central_data:
        driver: local
    postgres_time_mgmt_data:
        driver: local
    redis_data:
        driver: local
    nats_data:
        driver: local
    prometheus_data:
        driver: local
    grafana_data:
        driver: local
